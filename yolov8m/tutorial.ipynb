{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc9d231-f88a-4254-9dff-785cd92d163b",
   "metadata": {},
   "source": [
    "This YOLOv8 ðŸš€ notebook by Vitis AI presents simple train, validate and predict examples to help start your AI adventure.\n",
    "We hope that the resources in this notebook will help you get the most out of YOLOv8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d6162-9ebd-4b22-a501-a6d069c3d4cc",
   "metadata": {},
   "source": [
    "# Setup and Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d86a16c-3742-4e67-807c-bbd43e5f383c",
   "metadata": {},
   "source": [
    "Clone GitHub repository, install dependencies and check PyTorch and GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672615b-ff1a-41b4-bdc0-149cfe7a9e34",
   "metadata": {},
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89f5d64-e171-48b6-8ae1-895d3c28edde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://xcdpython.xilinx.com/simple\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /env/base/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /env/base/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.21.5)\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b61052-79ee-4a91-8c27-9985df18a7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running egg_info\n",
      "writing ultralytics.egg-info/PKG-INFO\n",
      "writing dependency_links to ultralytics.egg-info/dependency_links.txt\n",
      "writing entry points to ultralytics.egg-info/entry_points.txt\n",
      "writing requirements to ultralytics.egg-info/requires.txt\n",
      "writing top-level names to ultralytics.egg-info/top_level.txt\n",
      "reading manifest file 'ultralytics.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'ultralytics.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "Removing ultralytics 8.0.32 from easy-install.pth file\n",
      "Adding ultralytics 8.0.32 to easy-install.pth file\n",
      "Processing dependencies for ultralytics==8.0.32\n",
      "Searching for setuptools>=18.5\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "%cd code/\n",
    "!python setup.py develop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2b49c-4a87-46dd-9f70-c1882c45098e",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44507721-9dd3-4ae1-9773-c840ba3539a5",
   "metadata": {},
   "source": [
    "##### Download COCO2017 dataset.(refer to this repo https://github.com/ultralytics/ultralytics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf86ac7-7152-4574-a819-8d6f719948e1",
   "metadata": {},
   "source": [
    "### Put coco2017 dataset under the ./code/data directory, dataset directory structure like:\n",
    "```markdown\n",
    "+ data/\n",
    "    + coco/\n",
    "        + labels/\n",
    "        + annotations/\n",
    "        + images/\n",
    "        + test-dev2017.txt \n",
    "        + train2017.txt\n",
    "        + val2017.txt\n",
    "```\n",
    "### Modify the path of coco in coco.yaml to your custom dataset\n",
    "```\n",
    "path: /path/to/the/coco_dataset  # dataset root dir\n",
    "train: train2017.txt\n",
    "val: val2017.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a69f4-271e-4759-a412-f6b22f580cc1",
   "metadata": {},
   "source": [
    "# Train/Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a4d38-906f-4df5-af62-ba9674242dc6",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07455fb0-f2fa-433a-874c-f132c30c11cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.Detect                [80, [192, 384, 576]]         \n",
      "YOLOv8m summary: 337 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPs\n",
      "\n",
      "Ultralytics YOLOv8.0.32 ðŸš€ Python-3.7.12 torch-1.8.0 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=./../float/yolov8m.pt, data=datasets/coco.yaml, epochs=50, patience=50, batch=2, imgsz=640, save=True, cache=False, device=0, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, min_memory=False, sync_bn=False, nndct_quant=False, quant_mode=test, dump_xmodel=False, dump_onnx=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.1, cfg=None, v5loader=False, save_dir=runs/detect/train254\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.Detect                [80, [192, 384, 576]]         \n",
      "YOLOv8m summary: 337 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPs\n",
      "\n",
      "Transferred 475/475 items from pretrained weights\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50      1.59G      1.166      1.492       1.27         30        640:  \n"
     ]
    }
   ],
   "source": [
    "# for float training\n",
    "%cd code\n",
    "!CUDA_VISIBLE_DEVICES=0 yolo detect train data=\"datasets/coco.yaml\" model=./../float/yolov8m.pt pretrained=True epochs=50 batch=2 device=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c422080-9b55-44dc-bf0d-bbbc489c043c",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2caeadc8-a179-4fd3-b21f-0245b5dcd160",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.Detect                [80, [192, 384, 576]]         \n",
      "YOLOv8m summary: 337 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPs\n",
      "\n",
      "Ultralytics YOLOv8.0.32 ðŸš€ Python-3.7.12 torch-1.8.0 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
      "YOLOv8m summary (fused): 260 layers, 25886080 parameters, 58800 gradients, 78.9 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all       5000      36335      0.716      0.609      0.667      0.501\n",
      "                     0       5000      10777      0.821      0.745      0.828      0.616\n",
      "                     1       5000        314      0.742      0.525      0.627      0.402\n",
      "                     2       5000       1918      0.765      0.637      0.713      0.497\n",
      "                     3       5000        367      0.809      0.669      0.782      0.541\n",
      "                     4       5000        143       0.84      0.884      0.925      0.776\n",
      "                     5       5000        283       0.85      0.784      0.864       0.75\n",
      "                     6       5000        190       0.88      0.888      0.938      0.769\n",
      "                     7       5000        414      0.656       0.51      0.604      0.442\n",
      "                     8       5000        424      0.731      0.469      0.572      0.332\n",
      "                     9       5000        634      0.723      0.478       0.56      0.313\n",
      "                    10       5000        101      0.887      0.842      0.901      0.749\n",
      "                    11       5000         75      0.818       0.72      0.795      0.716\n",
      "                    12       5000         60      0.774      0.633      0.693       0.54\n",
      "                    13       5000        411      0.639      0.387       0.45      0.326\n",
      "                    14       5000        427       0.73      0.493       0.58      0.404\n",
      "                    15       5000        202      0.877      0.906      0.935      0.786\n",
      "                    16       5000        218      0.828      0.821      0.848      0.739\n",
      "                    17       5000        272      0.841      0.798      0.883      0.698\n",
      "                    18       5000        354      0.761      0.792      0.818      0.625\n",
      "                    19       5000        372       0.85      0.761       0.85      0.659\n",
      "                    20       5000        252      0.793      0.893      0.885      0.724\n",
      "                    21       5000         71      0.919      0.887      0.931      0.803\n",
      "                    22       5000        266      0.863      0.865      0.929      0.765\n",
      "                    23       5000        232       0.93      0.922      0.946      0.783\n",
      "                    24       5000        371      0.562      0.286      0.357      0.209\n",
      "                    25       5000        407      0.702      0.637      0.703      0.501\n",
      "                    26       5000        540      0.597      0.281      0.355      0.212\n",
      "                    27       5000        252      0.761      0.532      0.605      0.411\n",
      "                    28       5000        299      0.723      0.582      0.703      0.497\n",
      "                    29       5000        115      0.837      0.851       0.88      0.708\n",
      "                    30       5000        241      0.695      0.472      0.515      0.312\n",
      "                    31       5000         69      0.682      0.493      0.562      0.442\n",
      "                    32       5000        260      0.822      0.596      0.668      0.478\n",
      "                    33       5000        327      0.689      0.606       0.66      0.483\n",
      "                    34       5000        145      0.677        0.6      0.683      0.442\n",
      "                    35       5000        148      0.758      0.608      0.679      0.434\n",
      "                    36       5000        179      0.856      0.793       0.83      0.623\n",
      "                    37       5000        267      0.823      0.618      0.713      0.477\n",
      "                    38       5000        225      0.876      0.844      0.875      0.638\n",
      "                    39       5000       1013      0.707       0.56      0.635      0.451\n",
      "                    40       5000        341      0.746       0.55      0.649      0.438\n",
      "                    41       5000        895      0.688        0.6      0.657      0.501\n",
      "                    42       5000        215      0.704      0.586      0.658      0.484\n",
      "                    43       5000        325      0.577      0.338      0.419      0.278\n",
      "                    44       5000        253      0.554      0.356       0.42      0.296\n",
      "                    45       5000        623      0.654      0.581      0.632      0.486\n",
      "                    46       5000        370      0.584      0.349      0.444      0.297\n",
      "                    47       5000        236      0.478      0.297      0.324      0.233\n",
      "                    48       5000        177      0.642      0.567      0.599      0.477\n",
      "                    49       5000        285      0.525      0.389      0.438      0.342\n",
      "                    50       5000        312      0.579      0.394      0.457      0.267\n",
      "                    51       5000        365      0.462      0.397      0.379      0.248\n",
      "                    52       5000        125       0.72      0.504      0.574      0.441\n",
      "                    53       5000        284      0.753      0.736      0.779      0.613\n",
      "                    54       5000        328      0.686      0.585      0.649      0.525\n",
      "                    55       5000        310      0.673      0.552       0.63      0.429\n",
      "                    56       5000       1771      0.662      0.475      0.568      0.389\n",
      "                    57       5000        261      0.691      0.594      0.687      0.535\n",
      "                    58       5000        342       0.61      0.538      0.543       0.35\n",
      "                    59       5000        163      0.676       0.65      0.717      0.533\n",
      "                    60       5000        695      0.611      0.491      0.516      0.366\n",
      "                    61       5000        179      0.794      0.788      0.865      0.722\n",
      "                    62       5000        288      0.784      0.758       0.82      0.651\n",
      "                    63       5000        231      0.779      0.758      0.823      0.716\n",
      "                    64       5000        106       0.86      0.792      0.848      0.656\n",
      "                    65       5000        283      0.677      0.509      0.587      0.393\n",
      "                    66       5000        153       0.67      0.636      0.748      0.586\n",
      "                    67       5000        262      0.678      0.576      0.617      0.436\n",
      "                    68       5000         55      0.714      0.818      0.837      0.696\n",
      "                    69       5000        143      0.634      0.566      0.607      0.454\n",
      "                    70       5000          9      0.595      0.778      0.658      0.458\n",
      "                    71       5000        225       0.67      0.604      0.635      0.447\n",
      "                    72       5000        126      0.749      0.762      0.808       0.69\n",
      "                    73       5000       1129      0.583      0.189      0.302      0.174\n",
      "                    74       5000        267      0.762      0.727      0.772      0.565\n",
      "                    75       5000        274      0.663      0.609       0.62       0.45\n",
      "                    76       5000         36       0.67      0.417      0.448      0.375\n",
      "                    77       5000        190      0.741      0.692      0.743      0.585\n",
      "                    78       5000         11      0.329     0.0909     0.0813     0.0443\n",
      "                    79       5000         57      0.552      0.475      0.482      0.349\n",
      "Speed: 0.2ms pre-process, 9.7ms inference, 0.0ms loss, 1.3ms post-process per image\n",
      "Saving runs/detect/val/predictions.json...\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.44s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=3.90s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=48.69s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=8.70s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.671\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.545\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.557\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.634\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.510\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.743\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.832\n"
     ]
    }
   ],
   "source": [
    "%cd code\n",
    "!CUDA_VISIBLE_DEVICES=0 yolo detect val data=\"datasets/coco.yaml\" model=./../float/yolov8m.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf576e92-86e9-4599-8c32-c3bee7059855",
   "metadata": {},
   "source": [
    "## Quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fb25db1-2f47-4748-b519-a27f22341665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.Detect                [80, [192, 384, 576]]         \n",
      "YOLOv8m summary: 337 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPs\n",
      "\n",
      "Ultralytics YOLOv8.0.32 ðŸš€ Python-3.7.12 torch-1.8.0 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
      "NNDCT quant dir: ../float/nndct_quant\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: OS and CPU information:\n",
      "               system --- Linux\n",
      "              release --- 4.4.0-134-generic\n",
      "              version --- #160-Ubuntu SMP Wed Aug 15 14:58:00 UTC 2018\n",
      "              machine --- x86_64\n",
      "            processor --- x86_64\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Tools version information:\n",
      "                  GCC --- GCC 9.4.0\n",
      "               python --- 3.7.12\n",
      "              pytorch --- 1.8.0\n",
      "        vai_q_pytorch --- 3.5.0+ad8d88e+torch1.8.0\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: GPU information:\n",
      "          device name --- Tesla P100-PCIE-16GB\n",
      "     device available --- True\n",
      "         device count --- 1\n",
      "       current device --- 0\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization calibration process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing DetectionModel...\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model DetectionModel is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 3408.6\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Doing weights equalization...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(../float/nndct_quant/DetectionModel.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Get module with quantization.\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(../float/nndct_quant/quant_info.json)\u001b[0m\n",
      "                   all       5000      36335      0.671      0.554        0.6      0.433\n",
      "                     0       5000      10777      0.796      0.716      0.796      0.575\n",
      "                     1       5000        314       0.59      0.525      0.566      0.353\n",
      "                     2       5000       1918      0.686      0.634      0.669      0.451\n",
      "                     3       5000        367      0.783      0.649       0.74      0.488\n",
      "                     4       5000        143       0.86      0.811      0.879      0.699\n",
      "                     5       5000        283      0.796      0.799      0.839      0.714\n",
      "                     6       5000        190      0.831      0.852      0.892      0.696\n",
      "                     7       5000        414      0.621      0.539      0.568      0.403\n",
      "                     8       5000        424      0.663      0.422      0.491       0.26\n",
      "                     9       5000        634       0.73        0.4      0.507      0.281\n",
      "                    10       5000        101      0.891      0.802      0.873      0.706\n",
      "                    11       5000         75      0.819      0.665      0.752      0.668\n",
      "                    12       5000         60      0.741      0.567      0.594      0.446\n",
      "                    13       5000        411      0.505      0.404      0.394      0.278\n",
      "                    14       5000        427      0.649      0.468      0.506      0.343\n",
      "                    15       5000        202      0.732      0.822      0.817      0.656\n",
      "                    16       5000        218      0.707      0.761      0.772      0.631\n",
      "                    17       5000        272      0.812      0.812       0.83      0.637\n",
      "                    18       5000        354      0.707      0.763      0.765      0.548\n",
      "                    19       5000        372      0.863      0.677      0.788      0.589\n",
      "                    20       5000        252      0.747      0.841      0.846      0.669\n",
      "                    21       5000         71      0.846      0.773      0.821      0.666\n",
      "                    22       5000        266       0.82      0.857      0.902      0.716\n",
      "                    23       5000        232      0.888      0.892      0.918      0.745\n",
      "                    24       5000        371      0.599      0.197      0.293      0.164\n",
      "                    25       5000        407      0.695      0.609      0.651      0.437\n",
      "                    26       5000        540      0.551      0.222      0.294       0.17\n",
      "                    27       5000        252      0.827      0.436      0.546      0.342\n",
      "                    28       5000        299      0.665      0.471      0.558      0.378\n",
      "                    29       5000        115      0.818      0.817      0.869      0.672\n",
      "                    30       5000        241      0.666      0.448      0.498      0.266\n",
      "                    31       5000         69      0.603      0.462      0.503      0.383\n",
      "                    32       5000        260       0.77      0.542       0.61      0.427\n",
      "                    33       5000        327      0.729      0.468      0.576      0.403\n",
      "                    34       5000        145       0.76      0.523      0.598       0.37\n",
      "                    35       5000        148      0.771      0.588      0.637      0.386\n",
      "                    36       5000        179      0.768      0.777      0.771      0.555\n",
      "                    37       5000        267      0.759      0.554       0.64      0.409\n",
      "                    38       5000        225      0.771      0.795       0.83      0.562\n",
      "                    39       5000       1013      0.628      0.497      0.549      0.381\n",
      "                    40       5000        341      0.695      0.501      0.575      0.371\n",
      "                    41       5000        895      0.622      0.546      0.594      0.442\n",
      "                    42       5000        215      0.671      0.502      0.566      0.394\n",
      "                    43       5000        325      0.643      0.227      0.334      0.214\n",
      "                    44       5000        253      0.484        0.3        0.3      0.201\n",
      "                    45       5000        623      0.569       0.56      0.556      0.421\n",
      "                    46       5000        370      0.481      0.305      0.364      0.235\n",
      "                    47       5000        236      0.411      0.275      0.235      0.166\n",
      "                    48       5000        177      0.643      0.395      0.489      0.341\n",
      "                    49       5000        285      0.563      0.333      0.407      0.312\n",
      "                    50       5000        312      0.553      0.337       0.37      0.208\n",
      "                    51       5000        365      0.495      0.252      0.318      0.202\n",
      "                    52       5000        125      0.736      0.376      0.485      0.343\n",
      "                    53       5000        284      0.705      0.722       0.74      0.571\n",
      "                    54       5000        328      0.621      0.524      0.558      0.432\n",
      "                    55       5000        310      0.658      0.484      0.554      0.367\n",
      "                    56       5000       1771      0.591       0.46      0.504      0.332\n",
      "                    57       5000        261      0.513      0.632      0.593      0.449\n",
      "                    58       5000        342      0.526      0.515      0.471      0.291\n",
      "                    59       5000        163      0.597      0.607      0.609       0.42\n",
      "                    60       5000        695       0.56      0.443      0.448      0.309\n",
      "                    61       5000        179      0.686      0.754      0.773      0.625\n",
      "                    62       5000        288      0.692      0.694       0.74      0.574\n",
      "                    63       5000        231       0.72      0.745      0.786      0.655\n",
      "                    64       5000        106      0.829      0.774      0.803      0.618\n",
      "                    65       5000        283      0.574      0.385      0.462      0.299\n",
      "                    66       5000        153       0.75      0.646      0.723      0.545\n",
      "                    67       5000        262       0.69      0.408      0.505      0.352\n",
      "                    68       5000         55       0.54      0.745      0.776       0.61\n",
      "                    69       5000        143      0.564      0.497      0.545      0.387\n",
      "                    70       5000          9       0.53      0.556      0.427      0.305\n",
      "                    71       5000        225      0.615      0.547      0.588      0.393\n",
      "                    72       5000        126      0.615      0.722      0.749      0.605\n",
      "                    73       5000       1129      0.541      0.158      0.251      0.132\n",
      "                    74       5000        267      0.758      0.692      0.734      0.525\n",
      "                    75       5000        274       0.58      0.504      0.535      0.371\n",
      "                    76       5000         36      0.856       0.33      0.419      0.327\n",
      "                    77       5000        190      0.685      0.616      0.683      0.489\n",
      "                    78       5000         11          0          0     0.0519     0.0272\n",
      "                    79       5000         57       0.62      0.368        0.4      0.283\n",
      "Speed: 0.2ms pre-process, 84.5ms inference, 0.0ms loss, 0.7ms post-process per image\n",
      "Saving runs/detect/val/predictions.json...\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=4.48s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=50.77s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=10.98s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.604\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.473\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.562\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.641\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.470\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.696\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.799\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.Detect                [80, [192, 384, 576]]         \n",
      "YOLOv8m summary: 337 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPs\n",
      "\n",
      "Ultralytics YOLOv8.0.32 ðŸš€ Python-3.7.12 torch-1.8.0 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
      "NNDCT quant dir: ../float/nndct_quant\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: OS and CPU information:\n",
      "               system --- Linux\n",
      "              release --- 4.4.0-134-generic\n",
      "              version --- #160-Ubuntu SMP Wed Aug 15 14:58:00 UTC 2018\n",
      "              machine --- x86_64\n",
      "            processor --- x86_64\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Tools version information:\n",
      "                  GCC --- GCC 9.4.0\n",
      "               python --- 3.7.12\n",
      "              pytorch --- 1.8.0\n",
      "        vai_q_pytorch --- 3.5.0+ad8d88e+torch1.8.0\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: GPU information:\n",
      "          device name --- Tesla P100-PCIE-16GB\n",
      "     device available --- True\n",
      "         device count --- 1\n",
      "       current device --- 0\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization test process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing DetectionModel...\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model DetectionModel is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 292/292 [00:00<00:00, 3373.8\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Doing weights equalization...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(../float/nndct_quant/DetectionModel.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Get module with quantization.\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all       5000      36335      0.665      0.551      0.596      0.432\n",
      "                     0       5000      10777      0.741      0.719      0.779      0.564\n",
      "                     1       5000        314      0.587      0.507      0.563      0.351\n",
      "                     2       5000       1918      0.688      0.634      0.673      0.453\n",
      "                     3       5000        367      0.795      0.635      0.732      0.483\n",
      "                     4       5000        143      0.866      0.818      0.877      0.694\n",
      "                     5       5000        283      0.793      0.785      0.841      0.712\n",
      "                     6       5000        190      0.812      0.842      0.892      0.695\n",
      "                     7       5000        414      0.596      0.531       0.56      0.402\n",
      "                     8       5000        424       0.67      0.436      0.496      0.262\n",
      "                     9       5000        634      0.725      0.404      0.505      0.282\n",
      "                    10       5000        101      0.877      0.782      0.872      0.705\n",
      "                    11       5000         75      0.846      0.667      0.755      0.666\n",
      "                    12       5000         60      0.743      0.583      0.601      0.453\n",
      "                    13       5000        411       0.52      0.406        0.4      0.279\n",
      "                    14       5000        427      0.646      0.466      0.504      0.341\n",
      "                    15       5000        202      0.489      0.802      0.768      0.618\n",
      "                    16       5000        218      0.715      0.748      0.775      0.635\n",
      "                    17       5000        272        0.8      0.794       0.83      0.642\n",
      "                    18       5000        354      0.711      0.757      0.766      0.554\n",
      "                    19       5000        372      0.867      0.667      0.786      0.588\n",
      "                    20       5000        252      0.748      0.837      0.836      0.661\n",
      "                    21       5000         71      0.817      0.761      0.814       0.67\n",
      "                    22       5000        266      0.845      0.865      0.899      0.717\n",
      "                    23       5000        232      0.896      0.892      0.919      0.744\n",
      "                    24       5000        371      0.595      0.186      0.281      0.158\n",
      "                    25       5000        407      0.688      0.597       0.65      0.435\n",
      "                    26       5000        540      0.567      0.228      0.295      0.167\n",
      "                    27       5000        252      0.807      0.417      0.531      0.337\n",
      "                    28       5000        299      0.672      0.465      0.549      0.367\n",
      "                    29       5000        115      0.809       0.81      0.864      0.668\n",
      "                    30       5000        241      0.626      0.424      0.483      0.263\n",
      "                    31       5000         69      0.614      0.464      0.514      0.386\n",
      "                    32       5000        260      0.761      0.527      0.606      0.429\n",
      "                    33       5000        327      0.708      0.468      0.588      0.412\n",
      "                    34       5000        145      0.716      0.524      0.588      0.369\n",
      "                    35       5000        148      0.764      0.595      0.644      0.392\n",
      "                    36       5000        179      0.785      0.777      0.775      0.563\n",
      "                    37       5000        267      0.773      0.562      0.636      0.403\n",
      "                    38       5000        225      0.779        0.8       0.83      0.572\n",
      "                    39       5000       1013      0.634      0.504      0.543      0.379\n",
      "                    40       5000        341      0.706      0.507      0.573      0.375\n",
      "                    41       5000        895      0.629      0.546      0.591      0.437\n",
      "                    42       5000        215      0.655       0.47      0.552      0.389\n",
      "                    43       5000        325      0.602      0.228       0.32      0.209\n",
      "                    44       5000        253        0.5      0.308       0.31      0.208\n",
      "                    45       5000        623      0.572       0.56      0.559      0.422\n",
      "                    46       5000        370      0.502      0.316      0.372       0.23\n",
      "                    47       5000        236      0.395       0.28      0.221       0.16\n",
      "                    48       5000        177      0.631      0.407      0.478      0.335\n",
      "                    49       5000        285      0.566       0.32      0.401      0.306\n",
      "                    50       5000        312      0.558      0.327      0.364      0.207\n",
      "                    51       5000        365      0.492      0.247      0.317      0.201\n",
      "                    52       5000        125      0.705      0.384      0.478      0.339\n",
      "                    53       5000        284      0.698      0.718      0.746      0.576\n",
      "                    54       5000        328      0.629      0.527      0.559      0.427\n",
      "                    55       5000        310      0.651      0.487      0.555       0.37\n",
      "                    56       5000       1771      0.584      0.473      0.505      0.331\n",
      "                    57       5000        261      0.517      0.636      0.583      0.443\n",
      "                    58       5000        342      0.537      0.494      0.464      0.289\n",
      "                    59       5000        163      0.416      0.595      0.549      0.379\n",
      "                    60       5000        695      0.557      0.453      0.452      0.314\n",
      "                    61       5000        179      0.695      0.754      0.767      0.607\n",
      "                    62       5000        288      0.692      0.681      0.722      0.558\n",
      "                    63       5000        231      0.752      0.749       0.79      0.656\n",
      "                    64       5000        106      0.827      0.774      0.815      0.645\n",
      "                    65       5000        283       0.61      0.399      0.468      0.295\n",
      "                    66       5000        153        0.7      0.595      0.707      0.532\n",
      "                    67       5000        262      0.692       0.42      0.508      0.354\n",
      "                    68       5000         55      0.546      0.745       0.78      0.621\n",
      "                    69       5000        143      0.566      0.503      0.548      0.393\n",
      "                    70       5000          9      0.553      0.556      0.427      0.318\n",
      "                    71       5000        225      0.633       0.56      0.586      0.398\n",
      "                    72       5000        126      0.636      0.722      0.749      0.598\n",
      "                    73       5000       1129      0.542       0.16       0.25      0.132\n",
      "                    74       5000        267      0.741      0.685      0.728      0.516\n",
      "                    75       5000        274       0.59      0.515      0.536      0.371\n",
      "                    76       5000         36      0.909      0.306      0.432      0.332\n",
      "                    77       5000        190      0.698      0.622      0.677      0.482\n",
      "                    78       5000         11          0          0     0.0517     0.0252\n",
      "                    79       5000         57      0.616      0.368      0.377      0.269\n",
      "Speed: 0.2ms pre-process, 34.3ms inference, 0.0ms loss, 0.8ms post-process per image\n",
      "Saving runs/detect/val314/predictions.json...\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.76s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=4.61s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=54.80s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=12.54s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.601\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.563\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.591\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.641\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.459\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.696\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.796\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 yolo detect val data=\"datasets/coco.yaml\" model=./../float/yolov8m.pt \\\n",
    "    nndct_quant=True quant_mode=calib --nndct_convert_sigmoid_to_hsigmoid --nndct_convert_silu_to_hswish\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 yolo detect val data=\"datasets/coco.yaml\" model=./../float/yolov8m.pt \\\n",
    "    nndct_quant=True quant_mode=test --nndct_convert_sigmoid_to_hsigmoid --nndct_convert_silu_to_hswish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e34f8af-a6b2-4c5d-96ac-7f6ef206f514",
   "metadata": {},
   "source": [
    "### Performance\n",
    "| Model             | Input Size | Float mAP   | Quant mAP   | FLOPs  |\n",
    "|-------------------|------------|-------------|-------------|--------|\n",
    "| YOLOv8m           | 640*640    | 50.0%       | 48.7%       | 78.9G  |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
